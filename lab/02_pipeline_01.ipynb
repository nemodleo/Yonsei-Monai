{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ohkCyqZNaM"
   },
   "source": [
    "#  MONAI Bootcamp\n",
    "## End-To-End Workflow with MONAI\n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>\n",
    "\n",
    "Welcome to the MONAI bootcamp! This notebook will introduce you to an end-to-end workin in MONAI using both a standard PyTorch loop and using Ignite, followed by a hands-on implementing your own model using everything you've learned so far.\n",
    "\n",
    "#### Required Packages \n",
    "The servers running MONAI Bootcamp already have CUDA driver, CUDA toolkit 11.0, pytorch 1.6+, monai 0.8.1, and libraries for practice installed.\n",
    "\n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook in BYOD or colab environment.\n",
    "\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aLtpMbJVNCH",
    "outputId": "303f73d6-97d8-4b68-d023-30592acabcf8"
   },
   "outputs": [],
   "source": [
    "#!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==0.8.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7pcbsphZh8G"
   },
   "source": [
    "### Check GPU Support\n",
    "\n",
    "Running `!nvidia-smi` in a cell will verify this has worked and show you what kind of hardware you have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVD7911EVcWI",
    "outputId": "503408e7-e213-437c-e057-cdc082882214"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_lPbckSZsAG"
   },
   "source": [
    "# End-to-end Training with Pytorch and Ignite\n",
    "We've covered a lot of material and now it's time to apply the things that we've learned in an end-to-end example. First, we're going to use the basic PyTorch paradigm for training our model. We'll then look at how to train using the Ignite workflows to make things even easier!\n",
    "\n",
    "## End-to-End Training Workflow\n",
    "To help guide you through training your first model using MONAI, this guide will will cover five key phases:\n",
    "\n",
    " 1. Setting up our Dataset and exploring the data\n",
    " 2. Preparing datasets and transforms\n",
    " 3. Define your network and create our PyTorch training loop\n",
    " 4. Evaluate your model and understand the results\n",
    " 5. Start using Ignite and more about determinism\n",
    " \n",
    "Let's get started by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg9upTKtVga-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.data import decollate_batch, partition_dataset_classes\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBZIJLrJZ1IQ"
   },
   "source": [
    "## 1. Setting up our Dataset and exploring the data\n",
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called temp directory in `~/monai-lab/temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOX-pVqQVo01",
    "outputId": "cc1d2154-c38c-459b-92c9-4b9263447b90"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "directory = \"temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQQ26Fv9Z-xK"
   },
   "source": [
    "Download the MedNIST dataset\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions), [the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4), and the [NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license. If you use the MedNIST dataset, please acknowledge the source.\n",
    "\n",
    "We're going to download this dataset below and extract it into our temporary MONAI Data Directory.\n",
    "It will take about 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_yH3E2_VvX7",
    "outputId": "04200657-6aea-4747-ad99-efe377a0dce3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "resource = \"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccI6haMfaYSF"
   },
   "source": [
    "### Set deterministic training for reproducibility\n",
    "\n",
    "[`set_determinism`](https://docs.monai.io/en/latest/utils.html?highlight=set_determinism#monai.utils.misc.set_determinism) will set the random seeds in both Numpy and PyTorch to ensure reproducibility. We'll see later that we need to go a little bit further to ensure reproducibility in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwYpFBImV1hJ"
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uKHIr0Jaj2s"
   },
   "source": [
    "#### Read the image filenames from the dataset folders\n",
    "\n",
    "When using a dataset, you want to understand the basics of the images, labels, and more. We'll start off by showing some of those basic statistics for MedNIST.\n",
    "\n",
    "We'll see that 6 different folders are representing 6 different categories: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT. We'll be using each of these categories as our label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4T6KV7lV1ng",
    "outputId": "933bcb83-46c1-472d-b5db-c0e786b816c3"
   },
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "    \n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"number of Labels: {num_class}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93ekM9ZAV9lo"
   },
   "source": [
    "## Randomly pick images from the dataset to visualize and check\n",
    "We want to understand what the images we're using look like, so we'll start by visualizing a few random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "q0wzQOvUV1q3",
    "outputId": "34f9729e-1eae-42d4-bd0e-81e630582f66"
   },
   "outputs": [],
   "source": [
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = PIL.Image.open(image_files_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_class[k]])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx-WedqRWDbt"
   },
   "source": [
    "# 2. Preparing datasets and transforms\n",
    "### Prepare training, validation, and test data lists\n",
    "\n",
    "We want to split the data into 3 different sets, one for training, one for validation, and one for testing. We'll use a ratio of 80/10/10 for those sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vppWmX-BV1uN",
    "outputId": "74075068-0c62-4b37-8371-3cd0b9d0fa27"
   },
   "outputs": [],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "train_x = list()\n",
    "train_y = list()\n",
    "val_x = list()\n",
    "val_y = list()\n",
    "test_x = list()\n",
    "test_y = list()\n",
    "\n",
    "for i in range(num_total):\n",
    "    rann = np.random.random()\n",
    "    if rann < val_frac:\n",
    "        val_x.append(image_files_list[i])\n",
    "        val_y.append(image_class[i])\n",
    "    elif rann < test_frac + val_frac:\n",
    "        test_x.append(image_files_list[i])\n",
    "        test_y.append(image_class[i])\n",
    "    else:\n",
    "        train_x.append(image_files_list[i])\n",
    "        train_y.append(image_class[i])\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQKPHOjgWHoW"
   },
   "source": [
    "### Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "\n",
    "We'll define our transform using `Compose`. In this Array of Transforms, we'll load the image, add a channel, scale its intensity, utilize a few random functions and finally create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaRvhLd-WTmF",
    "outputId": "619dac29-2ec4-4bb3-bf52-9bf49780c17e"
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), AddChannel(), ScaleIntensity(), ToTensor()])\n",
    "\n",
    "act = Compose([EnsureType(), Activations(softmax=True)])\n",
    "to_onehot = Compose([EnsureType(), AsDiscrete(to_onehot=num_class, n_classes=num_class)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DeElxN0WcKt"
   },
   "source": [
    "### Initialise the datasets and loaders for training, validation and test sets\n",
    "- Define a simple dataset, that we'll call `MedNISTDataset`, that  groups:\n",
    "\n",
    " - Images\n",
    " - Labels\n",
    " - The transforms that are to be run on the images and labels\n",
    "- Create three instances of this dataset:\n",
    "  - One for training\n",
    "  - One for validation\n",
    "  - One for testing\n",
    "\n",
    "We'll use a batch size of 512 and employ 10 workers to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fag4Yd2CWTum",
    "outputId": "af0aca02-0916-4909-9da7-8a14f57c1a20"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 10\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df90U_QrW0i6"
   },
   "source": [
    "3. Define your network and create our PyTorch training loop\n",
    "Define network and optimizer\n",
    "Set learning_rate for how much the model is updated per step\n",
    "The fetch a pytorch device for the GPU\n",
    "Instantiate a `densenet121` model instance and 'send' it to the GPU using device\n",
    "This is a standard MONAI implementation; it is capable of 2D and 3D operation but here we are using it in 2D mode\n",
    "We'll make use of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0Fxk7CNWTxg"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyIfXHW9W3rW"
   },
   "source": [
    "Network training\n",
    "We are hand-rolling a basic pytorch training loop here:\n",
    "\n",
    "standard pytorch training loop\n",
    "step through each training epoch, running through the training set in batches\n",
    "after each epoch, run a validation pass, evaluating the network\n",
    "if it shows improved performance, save out the model weights\n",
    "later we will revisit training loops in a more Ignite / MONAI fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8lVR-2UWT1M",
    "outputId": "41307ce0-1150-468e-af80-8116b76608b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epoch_num = 4\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "auc_metric = ROCAUCMetric()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    step = 1\n",
    "\n",
    "    steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "    # put the network in train mode; this tells the network and its modules to\n",
    "    # enable training elements such as normalisation and dropout, where applicable\n",
    "    net.train()\n",
    "    for batch_data in train_loader:\n",
    "\n",
    "        # move the data to the GPU\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "\n",
    "        # prepare the gradients for this step's back propagation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run the network forwards\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # run the loss function on the outputs\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # tell the optimizer to update the weights according to the gradients\n",
    "        # and its internal optimisation strategy\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size + 1}, training_loss: {loss.item():.4f}\")\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # after each epoch, run our metrics to evaluate it, and, if they are an improvement,\n",
    "    # save the model out\n",
    "    \n",
    "    # switch off training features of the network for this pass\n",
    "    net.eval()\n",
    "\n",
    "    # 'with torch.no_grad()' switches off gradient calculation for the scope of its context\n",
    "    with torch.no_grad():\n",
    "        # create lists to which we will concatenate the the validation results\n",
    "        preds = list()\n",
    "        labels = list()\n",
    "\n",
    "        # iterate over each batch of images and run them through the network in evaluation mode\n",
    "        for val_data in val_loader:\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "\n",
    "            # run the network\n",
    "            val_pred = net(val_images)\n",
    "\n",
    "            preds.append(val_pred)\n",
    "            labels.append(val_labels)\n",
    "\n",
    "        # concatenate the predicted labels with each other and the actual labels with each other\n",
    "        y_pred = torch.cat(preds)\n",
    "        y = torch.cat(labels)\n",
    "\n",
    "        # we are using the area under the receiver operating characteristic (ROC) curve to determine\n",
    "        # whether this epoch has improved the best performance of the network so far, in which case\n",
    "        # we save the network in this state\n",
    "        y_onehot = [to_onehot(i) for i in decollate_batch(y)]        \n",
    "        y_pred_act = [act(i) for i in decollate_batch(y_pred)]\n",
    "        \n",
    "        auc_metric(y_pred_act, y_onehot)\n",
    "        auc_value = auc_metric.aggregate()\n",
    "        auc_metric.reset()\n",
    "        metric_values.append(auc_value)\n",
    "        \n",
    "        acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "        acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "        \n",
    "        if auc_value > best_metric:\n",
    "            best_metric = auc_value\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(net.state_dict(), os.path.join(root_dir, \"mednist_model_best.pth\"))\n",
    "            print(\"saved new best metric network\")\n",
    "            \n",
    "        print(\n",
    "            f\"current epoch: {epoch + 1} current AUC: {auc_value:.4f} /\"\n",
    "            f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f} /\"\n",
    "            f\" at epoch: {best_metric_epoch}\"\n",
    "        )\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VypOnZ4CXMKt"
   },
   "source": [
    "### Plot the loss and metric\n",
    "Once we're done training we want to visualize our Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "r0pAunB0V1xr",
    "outputId": "322b0414-6793-4968-b215-15505373ba4b"
   },
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [(i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-bdaUzZXSfZ"
   },
   "source": [
    "## 4. Evaluate your model and understand the results\n",
    "### Evaluate the model on the test dataset\n",
    "\n",
    "After training and validation, we now have the best model as determined by the validation dataset. But now we need to evaluate the model on the test dataset to check whether the final model is robust and not over-fitting. We'll use these predictions to generate a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9cOS3oxXXVL",
    "outputId": "18a8a986-8c2b-4213-863d-2fa07f95c4fb"
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(os.path.join(root_dir, \"mednist_model_best.pth\")))\n",
    "net.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = net(test_images).argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDNY3EcJXZsH"
   },
   "source": [
    "### Some light analytics - classification report\n",
    "\n",
    "We'll utilize scikit-learn's classification report to get the precision, recall, and f1-score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IrTB-8YXcaN",
    "outputId": "0a408fd8-c9f6-4dc3-ccab-073a2820d6d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBLNwRarXs_V"
   },
   "source": [
    "### Some light analytics - confusion matrix\n",
    "\n",
    "Let's also create a confusion matrix to get a better understanding of the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "mJgK0RV0Xpmi",
    "outputId": "455b08f0-ae6c-40fb-9d63-f9b29827dcfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion_matrix(y_true, y_pred), cmap=\"terrain\", interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+class_names, rotation=270)\n",
    "ax.set_yticklabels(['']+class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution !!!\n",
    "### please shutdown all kernels with [Kernel] menu >  [Shutdown All Kernel]  before launch next notebook\n",
    "\n",
    "## Navigation\n",
    "- [01_getting started](./01_getting.ipynb)\n",
    "\n",
    "- [02_pipeline_01](./02_pipeline_01.ipynb)\n",
    "- [02_pipeline_02 Next](./02_pipeline_02.ipynb)\n",
    "- [02_pipeline_03](./02_pipeline_03.ipynb)\n",
    "- [02_pipeline_04](./02_pipeline_04.ipynb)\n",
    "\n",
    "- [03_brain_gan ](./03_brain_gan_01.ipynb)\n",
    "\n",
    "- [04_spleen_segment](./04_spleen_segment.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac baseline](./05_challenge_cardiac_baseline.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac workspace](./05_challenge_cardiac_workspace.ipynb) \n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Monai_bootcamp_01_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
