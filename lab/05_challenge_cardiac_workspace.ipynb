{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ohkCyqZNaM"
   },
   "source": [
    "#  MONAI Bootcamp\n",
    "\n",
    "# Segmentation Exercise  [workspace]\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>\n",
    "\n",
    "\n",
    "In this exercise we will segment the left ventricle of the heart in relatively small images using neural networks. \n",
    "Below is the code for setting up a segmentation network and training it. The network isn't very good, **so the exercise is to improve the quality of the segmentation by improving the network and/or the training scheme including data loading efficiency and data augmentation**. \n",
    "\n",
    "The data being used here is derived from the [Sunnybrook Cardiac Dataset](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/) of cardiac MR images, filtered to contain only left ventricular myocardium segmentations and reduced in the XY dimensions.\n",
    "\n",
    "<img src=\"https://www.cardiacatlas.org/wp-content/uploads/2015/09/scd-mri.png\" width=400>\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Challenge: Improve Results and Implementation ðŸ‘ˆ\n",
    "\n",
    "### 1. Improve Data Pipeline\n",
    "\n",
    "The pipeline currently has a very basic set of transforms. We'd want to add new transforms which will add regularization to our training process, specifically modifying the image and segmentations to make the learning problem a little harder. \n",
    "\n",
    "The dataset being used is `ArrayDataset` but we have in MONAI `NPZDictItemDataset` for loading data from Numpy's NPZ file format. Change the code to use this class instead. You'll need a different way of getting `caseIndices` and splitting the dataset using it.\n",
    "\n",
    "### 2. Improve/Replace Network\n",
    "\n",
    "As you can see we're not getting good results from our network. The training loss values are jumping around and not decreasing much anymore. The validation score has topped out at 0.25, which is really poor. \n",
    "\n",
    "It's now up to you to improve the results of our segmentation task. The things to consider changing include the network itself, how data is loaded, how batches might be composed, and what transforms we want to use from MONAI. \n",
    "\n",
    "### 3. Replace The Training Loop\n",
    "\n",
    "This notebook uses a simple training loop with validation done explicitly. Replace this with a use of the `SupervisedTrainer` class and `SupervisedEvaluator` to do the evaluation throughout the training process. The graph plotting is done simply by recording values at each iteration through the loop, you'll want to use some other mechanism to do the same thing such as using a `MetricLogger` handler object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7pcbsphZh8G"
   },
   "source": [
    "### Check GPU Support\n",
    "\n",
    "Running  `!nvidia-smi` in a cell will verify this has worked and show you what kind of hardware you have access to.\n",
    "\n",
    "if GPU Memory Usage is no `0 MiB` shutdown all kernels and restart current kernel.\n",
    "- step1. shutdown kernel with following <b>Menu</b> > <b>Kernel</b> > <b>Shut Down All kernels </b>\n",
    "- step2. restart kernelw with following <b>Menu</b> > <b>Kernel</b> > <b>Restart Kernel</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVD7911EVcWI",
    "outputId": "2783c3a4-855a-4b2b-86c0-297b7b31b9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  7 10:18:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:0F:00.0 Off |                   On |\n",
      "| N/A   30C    P0    77W / 400W |     39MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    3   0   0  |     13MiB / 19968MiB | 28      0 |  2   0    1    0    0 |\n",
      "|                  |      0MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX4DkxZygKNP"
   },
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNnKTuzBgKZm",
    "outputId": "8b7c3607-768e-4222-d4c0-82806f5a1264"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.transforms import Compose, AddChannel, ScaleIntensity, ToTensor\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import ArrayDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.utils import first, progress_bar\n",
    "from monai.networks import one_hot\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "set_determinism(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up our Dataset and exploring the data\n",
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called temp directory in `~/monai-lab/temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "directory = \"temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpNZjqg3Lq-1"
   },
   "source": [
    "## download dataset \n",
    "\n",
    "We will use preprocessed Sunnybrook Cardiac MRI dataset (2MB) at  [VPH Summer SChool 2019](https://www.vph-institute.org/events/2019-vph-summer-school.html)\n",
    "\n",
    "You can check for further research\n",
    "- Sunnybrook Cardiac MRI dataset(30MB) in [kaggle](https://www.kaggle.com/datasets/salikhussaini49/sunnybrook-cardiac-mri)\n",
    "- Sunnybrook Cardiac Data DICOM file(2.6GB) at [Cardiac Atlas Project](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "DATA_NPZ = \"https://github.com/ericspod/VPHSummerSchool2019/raw/master/scd_lvsegs.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data from the remote source and visualize a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 ms, sys: 4.56 ms, total: 46.2 ms\n",
      "Wall time: 703 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remote_file = urlopen(DATA_NPZ)\n",
    "npz = BytesIO(remote_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 64, 64) (420, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c9e01eee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load(npz)  # load all the data from the archive\n",
    "\n",
    "images = data[\"images\"]  # images in BHW array order\n",
    "segs = data[\"segs\"]  # segmentations in BHW array order\n",
    "case_indices = data[\"caseIndices\"]  # the indices in `images` for each case\n",
    "\n",
    "images = images.astype(np.float32) / images.max()  # normalize images\n",
    "\n",
    "print(images.shape, segs.shape)\n",
    "plt.imshow(images[13] + segs[13] * 0.25, cmap=\"gray\")  # show image 13 with segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our data into a training and validation set by keeping the last 6 cases as the latter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline [start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "valid_index = case_indices[-6, 0]  # keep the last 6 cases for testing\n",
    "\n",
    "# divide the images, segmentations, and categories into train/test sets\n",
    "train_images, train_segs = images[:valid_index], segs[:valid_index]\n",
    "valid_images, valid_segs = images[valid_index:], segs[valid_index:]\n",
    "\n",
    "batch_size = 50\n",
    "num_workers = 2\n",
    "\n",
    "image_trans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),  # rescale image data to range [0,1]\n",
    "        AddChannel(),  # add 1-size channel dimension\n",
    "        ToTensor(),  # convert to tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "seg_trans = Compose([AddChannel(), ToTensor()])\n",
    "\n",
    "ds = ArrayDataset(train_images, image_trans, train_segs, seg_trans)\n",
    "loader = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_ds = ArrayDataset(valid_images, image_trans, valid_segs, seg_trans)\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "im, seg = first(loader)\n",
    "print(im.shape, im.min(), im.max(), seg.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a MONAI data loading object to compose batches during training, and another for validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline [end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Improve Data Pipeline\n",
    "\n",
    "The pipeline currently has a very basic set of transforms. We'd want to add new transforms which will add regularization to our training process, specifically modifying the image and segmentations to make the learning problem a little harder. \n",
    "\n",
    "The dataset being used is `ArrayDataset` but we have in MONAI `NPZDictItemDataset` for loading data from Numpy's NPZ file format. Change the code to use this class instead. You'll need a different way of getting `caseIndices` and splitting the dataset using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Activationsd, \n",
    "    AsDiscreted,\n",
    "    AddChanneld,\n",
    "    ScaleIntensityd,\n",
    "    CastToTyped,\n",
    "    EnsureTyped,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandZoomd,\n",
    "    Rand2DElasticd,\n",
    "    RandAffined,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new imports\n",
    "from monai.data import  NPZDictItemDataset #TODO  #ArrayDataset  to NPZDictItemDataset\n",
    "\n",
    "############\n",
    "batch_size = 2048\n",
    "num_workers = 4 #2\n",
    "aug_prob = 0.5\n",
    "############\n",
    "from monai.transforms import (\n",
    "    Activationsd, \n",
    "    AsDiscreted,\n",
    "    AddChanneld,\n",
    "    ScaleIntensityd,\n",
    "    CastToTyped,\n",
    "    EnsureTyped,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandZoomd,\n",
    "    Rand2DElasticd,\n",
    "    RandAffined,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need a different way of getting caseIndices and splitting the dataset using it. In the baseline, We split our data into a training and validation set by keeping the last 6 cases as the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# use these when interpolating binary segmentations to ensure values are 0 or 1 only\n",
    "zoom_mode = monai.utils.enums.InterpolateMode.NEAREST\n",
    "elast_mode = monai.utils.enums.GridSampleMode.BILINEAR, monai.utils.enums.GridSampleMode.NEAREST\n",
    "\n",
    "#########\n",
    "# for keys \n",
    "from monai.utils.enums import CommonKeys\n",
    "both_keys =  (CommonKeys.IMAGE, CommonKeys.LABEL) #(None, None) # TODO\n",
    "image_only = CommonKeys.IMAGE #None #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = Compose(\n",
    "    [\n",
    "        CastToTyped(image_only, (np.float32)),\n",
    "        ScaleIntensityd(image_only),\n",
    "        AddChanneld(both_keys),\n",
    "        RandRotate90d(keys=both_keys, prob=aug_prob),\n",
    "        RandFlipd(keys=both_keys, prob=aug_prob),\n",
    "        RandZoomd(keys=both_keys, prob=aug_prob, mode=zoom_mode),\n",
    "        Rand2DElasticd(keys=both_keys, prob=aug_prob, spacing=10, magnitude_range=(-2, 2), mode=elast_mode),\n",
    "#         RandAffined(keys=both_keys, prob=aug_prob, rotate_range=1, translate_range=16, mode=elast_mode),\n",
    "        CastToTyped(both_keys, (np.float32, np.int32)),\n",
    "        EnsureTyped(both_keys),\n",
    "#         AddChanneld(both_keys),  # add 1-size channel dimension\n",
    "#         ToTensor(both_keys),  # convert to tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_trans = Compose(\n",
    "    [\n",
    "        CastToTyped(image_only, (np.float32)),\n",
    "        ScaleIntensityd(image_only),\n",
    "        AddChanneld(both_keys),\n",
    "        CastToTyped(both_keys, (np.float32, np.int32)),\n",
    "        EnsureTyped(both_keys),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a MONAI data loading object to compose batches during training, and another for validation: However, we need to replace `ArrayDataset` `ArrayDataset(train_images, image_trans, train_segs, seg_trans)` with `NPZDictItemDataset`\n",
    "\n",
    "check MONAI document for [NPZDictItemDataset](https://docs.monai.io/en/stable/data.html?highlight=NPZDictItemDataset#npzdictitemdataset)\n",
    "\n",
    "class monai.data.<b>NPZDictItemDataset</b>(`npzfile, keys, transform=None, other_keys=()`)\n",
    "\n",
    "Represents a dataset from a loaded NPZ file. The members of the file to load are named in the keys of keys and stored under the keyed name. All loaded arrays must have the same 0-dimension (batch) size. Items are always dicts mapping names to an item extracted from the loaded arrays. If passing slicing indices, will return a PyTorch Subset, for example: data: Subset = dataset[1:4], for more details, please check: https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
    "\n",
    "Parameters\n",
    "- <b>npzfile</b> (`Union[str, IO]`) â€“ Path to .npz file or stream containing .npz file data\n",
    "- <b>keys</b> (`Dict[str, str]`) â€“ Maps keys to load from file to name to store in dataset\n",
    "- <b>transform</b> (`Optional[Callable[â€¦, Dict[str, Any]]]`) â€“ Transform to apply to batch dict\n",
    "- <b>other_keys</b> (`Optional[Sequence[str]]`) â€“ secondary data to load from file and store in dict other_keys, not returned by __getitem__\n",
    "- <b>data</b> â€“ input data to load and transform to generate dataset for model.\n",
    "- <b>transform</b> â€“ a callable data transform on input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for keys \n",
    "from monai.utils.enums import CommonKeys\n",
    "\n",
    "# create training and validation datasets from the whole set of images, these will be resized below based on case indices\n",
    "\n",
    "keys_train = {\"images\": CommonKeys.IMAGE, \"segs\": CommonKeys.LABEL} #TODO\n",
    "keys_val =  {\"images\": CommonKeys.IMAGE, \"segs\": CommonKeys.LABEL} # TODO\n",
    "\n",
    "train_dat = NPZDictItemDataset( npz, keys_train , train_trans  , (\"caseIndices\",) ) #TODO #ArrayDataset  to NPZDictItemDataset\n",
    "val_dat   = NPZDictItemDataset( npz, keys_val , val_trans  ) #TODO  #ArrayDataset  to NPZDictItemDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(image, label)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CommonKeys.IMAGE, CommonKeys.LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configure  train_loader and val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the case indices array\n",
    "case_indices = train_dat.other_keys[\"caseIndices\"] # TODO data[\"caseIndices\"]   to train_dat\n",
    "val_index = case_indices[-6, 0]  # keep the last 6 cases for testing\n",
    "\n",
    "\n",
    "train_dat = train_dat[:val_index]\n",
    "val_dat = val_dat[val_index:]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dat,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dat,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 52\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dat), len(val_dat))\n",
    "print(len(train_loader), len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define out simple network. This doesn't do a good job so consider how to improve it by adding layers or other elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monai Network\n",
    "MONAI provides predefined networks. we can easily import it. \n",
    "\n",
    "- [Layers](https://docs.monai.io/en/stable/networks.html#layers) : Act, Conv, Norm, Dropout, Flatten, Reshape, Pad, Pool, SkipConnection\n",
    "- [Blocks](https://docs.monai.io/en/stable/networks.html#module-monai.networks.blocks) : ADN, Convolution, Synamic UnetBlock, FCN, GCN, Squeeze-andExcitation, ResNeXt, SABlock, Transformer Block, \n",
    "- [Nets](https://docs.monai.io/en/stable/networks.html#nets)  : DenseNet121, EfficientNet, SegResNet, ResNet, SENet154, DyUNet, UNet, AutoEncoder, VarAutoEncoder, ViT, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define out simple network. This doesn't do a good job so consider how to improve it by adding layers or other elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model \n",
    "\n",
    "SegNet : \n",
    " - Input \n",
    " - Conv2D\n",
    " - MaxPool2D\n",
    " - Conv3D\n",
    " - ConvT2D\n",
    " - Conv2d\n",
    " - Output \n",
    "\n",
    "<p><img align='left' src=\"https://miro.medium.com/max/1400/1*nGFy96r63GwSE_EsJDLMDw.png\" width=600>  </p>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # layer 1: convolution, normalization, downsampling\n",
    "            nn.Conv2d(1, 2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            # layer 2\n",
    "            nn.Conv2d(2, 4, 3, 1, 1),\n",
    "            # layer 3\n",
    "            nn.ConvTranspose2d(4, 2, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            # layer 4: output\n",
    "            nn.Conv2d(2, 1, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "net = SegNet()\n",
    "net = net.to(device)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Challenge: Improve Results and Implementation ðŸ‘ˆ\n",
    "\n",
    "\n",
    "### 2. Improve/Replace Network\n",
    "\n",
    "As you can see we're not getting good results from our network. The training loss values are jumping around and not decreasing much anymore. The validation score has topped out at 0.25, which is really poor. \n",
    "\n",
    "It's now up to you to improve the results of our segmentation task. The things to consider changing include the network itself, how data is loaded, how batches might be composed, and what transforms we want to use from MONAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model \n",
    "\n",
    "### UNet\n",
    "\n",
    "[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)\n",
    "U Shaped Network was developed by Olaf Ronneberger et al. for Bio Medical Image Segmentation. \n",
    "It is Fully Convolutional Network Model for the segmentation task with two paths(encoder and decoder) with 1x1 convolution skip connection similar as residual. \n",
    "<img src=\"https://miro.medium.com/max/1400/1*J3t2b65ufsl1x6caf6GiBA.png\" width=800>\n",
    "\n",
    "#### UNet in monai.networks\n",
    "class monai.networks.nets.<b>UNet </b> (`spatial_dims, in_channels, out_channels, channels, strides, kernel_size=3, up_kernel_size=3, num_res_units=0, act='PRELU', norm='INSTANCE', dropout=0.0, bias=True, dimensions=None` )\n",
    "Enhanced version of <br>UNet</b> which has residual units implemented with the `ResidualUnit` class. The residual part uses a convolution to change the input dimensions to match the output dimensions if this is necessary but will use `nn.Identity` if not. Refer to: [Link](https://link.springer.com/chapter/10.1007/978-3-030-12029-0_40).\n",
    "\n",
    "Each layer of the network has a encode and decode path with a skip connection between them. Data in the encode path is downsampled using strided convolutions (if strides is given values greater than 1) and in the decode path upsampled using strided transpose convolutions. These down or up sampling operations occur at the beginning of each block rather than afterwards as is typical in <b>UNet</b> implementations.\n",
    "\n",
    "To further explain this consider the first example network given below. This network has 3 layers with strides of 2 for each of the middle layers (the last layer is the bottom connection which does not down/up sample). Input data to this network is immediately reduced in the spatial dimensions by a factor of 2 by the first convolution of the residual unit defining the first layer of the encode part. The last layer of the decode part will upsample its input (data from the previous layer concatenated with data from the skip connection) in the first convolution. this ensures the final output of the network has the same shape as the input.\n",
    "\n",
    "Padding values for the convolutions are chosen to ensure output sizes are even divisors/multiples of the input sizes if the strides value for a layer is a factor of the input sizes. A typical case is to use strides values of 2 and inputs that are multiples of powers of 2. An input can thus be downsampled evenly however many times its dimensions can be divided by 2, so for the example network inputs would have to have dimensions that are multiples of 4. In the second example network given below the input to the bottom layer will have shape `(1, 64, 15, 15)` for an input of shape `(1, 1, 240, 240)` demonstrating the input being reduced in size spatially by 2**4.\n",
    "\n",
    "##### Parameters\n",
    " - <b>spatial_dims </b>(`int`)  â€“ number of spatial dimensions.\n",
    " - <b>in_channels </b>(`int`) â€“ number of input channels.\n",
    " - <b>out_channels </b>(`int`) â€“ number of output channels.\n",
    " - <b>channels</b> (`Sequence[int]`) â€“ sequence of channels. Top block first. The length of channels should be no less than 2.\n",
    " - <b>strides</b> (`Sequence[int]`) â€“ sequence of convolution strides. The length of stride should equal to len(channels) - 1.\n",
    " - <b>kernel_size</b> (`Union[Sequence[int], int]`) â€“ convolution kernel size, the value(s) should be odd. If sequence, its length should equal to dimensions. Defaults to 3.\n",
    " - <b>up_kernel_size</b> (`Union[Sequence[int], int]`) â€“ upsampling convolution kernel size, the value(s) should be odd. If sequence, its length should equal to dimensions. Defaults to 3.\n",
    " - <b>num_res_units</b>  (`int`)â€“ number of residual units. Defaults to 0.\n",
    " - <b>act</b> (`Union[Tuple, str]`) â€“ activation type and arguments. Defaults to PReLU.\n",
    " - <b>norm</b> (`Union[Tuple, str]`) â€“ feature normalization type and arguments. Defaults to instance norm.\n",
    " - <b>dropout</b> (`float`) â€“ dropout ratio. Defaults to no dropout.\n",
    " - <b>bias (`bool`)</b> â€“ whether to have a bias term in convolution blocks. Defaults to True. According to Performance Tuning Guide, if a conv layer is directly followed by a batch norm layer, bias should be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import AutoEncoder\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "net = AutoEncoder( spatial_dims =2, in_channels=1, out_channels=1, channels=(4, 8, 16, 32),  strides=(2, 2, 2, 2), ) \n",
    "#net = AutoEncoder( spatial_dims =2, in_channels=1, out_channels=1, channels=(8, 16, 32, 64), strides=(2, 2, 2, 2), )\n",
    "#net = UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=[16, 32, 64], strides=[2, 2], num_res_units=2, dropout=0.2) # 3 layers \n",
    "#net = UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=[4, 8, 16], strides=[2, 2], num_res_units=2, dropout=0.2) # 3 layers \n",
    "#net = UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=[4, 8, 16, 32,64], strides=[2,2, 2,2], num_res_units=3, dropout=0.4) # 5 layers\n",
    "#net = UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=[16, 32, 64, 128, 256], strides=[2, 2, 2, 2], num_res_units=4, dropout=0.2) # 5 layers\n",
    "#net = UNet(spatial_dims=2, in_channels=1, out_channels=1, channels=[4, 8, 16, 32,64, 128,256], strides=[2, 2, 2, 2,2,2], num_res_units=6, dropout=0.2) # 7 layers\n",
    "\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "loss = DiceLoss(sigmoid=True)\n",
    "metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "#         print()\n",
    "#         print(inputs.dtype, targets.dtype)\n",
    "#         print(inputs[:5], targets[:5])\n",
    "        BCE = F.binary_cross_entropy(inputs, targets.float(), reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE\n",
    "    \n",
    "loss = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop [Baseline]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "step_losses = []\n",
    "epoch_metrics = []\n",
    "total_step = 0\n",
    "num_epochs = 200\n",
    "\n",
    "print(\"start train\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "\n",
    "    # train network with training images\n",
    "    for bimages, bsegs in loader:\n",
    "        bimages = bimages.to(device)\n",
    "        bsegs = bsegs.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        prediction = net(bimages)\n",
    "        loss_val = loss(torch.sigmoid(prediction), bsegs)\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "\n",
    "        step_losses.append((total_step, loss_val.item()))\n",
    "        total_step += 1\n",
    "\n",
    "    net.eval()\n",
    "    metric_vals = []\n",
    "\n",
    "    # test our network using the validation dataset\n",
    "    with torch.no_grad():\n",
    "        for bimages, bsegs in val_loader:\n",
    "            bimages = bimages.to(device)\n",
    "            bsegs = bsegs.to(device)\n",
    "\n",
    "            #prediction = net(bimages)\n",
    "\n",
    "            mvals = metric(y_pred=torch.sigmoid(prediction) > 0.5, y=bsegs)\n",
    "            metric_vals += mvals.cpu().data.numpy().flatten().tolist()\n",
    "\n",
    "    epoch_metrics.append((total_step, np.average(metric_vals)))\n",
    "\n",
    "    progress_bar(epoch + 1, num_epochs, f\"Validation Metric: {epoch_metrics[-1][1]:7.3}\")\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now graph the results from our training and find the results are not very good:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Challenge: Improve Results and Implementation ðŸ‘ˆ\n",
    "\n",
    "### 3. Replace The Training Loop\n",
    "\n",
    "This notebook uses a simple training loop with validation done explicitly. Replace this with a use of the `SupervisedTrainer` class and `SupervisedEvaluator` to do the evaluation throughout the training process. The graph plotting is done simply by recording values at each iteration through the loop, you'll want to use some other mechanism to do the same thing such as using a `MetricLogger` handler object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ignite\n",
    "in the end-to-end pipeline notebook,  we already use   `SupervisedTrainer` and `SupervisedEvaluator`. \n",
    "use MedNIST pipeline 03 and 04 for reference code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_losses = []\n",
    "epoch_metrics = []\n",
    "metric_values = []\n",
    "iter_losses=[]\n",
    "batch_sizes=[]\n",
    "epoch_loss_values =[]\n",
    "total_step = 0\n",
    "max_epochs = 200\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, Activationsd, AsDiscreted\n",
    "\n",
    "post_transform = Compose(\n",
    "    [Activationsd(keys=\"pred\", sigmoid=True), AsDiscreted(keys=[\"pred\", \"label\"], threshold_values=True,),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.handlers import StatsHandler, MeanDice, from_engine\n",
    "from monai.engines import SupervisedEvaluator\n",
    "\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device= device, #TODO\n",
    "    val_data_loader= val_loader, #TODO\n",
    "    network=net , #TODO\n",
    "    postprocessing= post_transform, #TODO\n",
    "    key_val_metric={\"val_mean_dice\": MeanDice(include_background=True, output_transform=from_engine([\"pred\", \"label\"]))},\n",
    "    val_handlers=[StatsHandler(output_transform=lambda x: None)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 2048 1\n"
     ]
    }
   ],
   "source": [
    "from monai.handlers import MetricLogger, ValidationHandler\n",
    "from monai.engines import SupervisedTrainer\n",
    "\n",
    "logger = MetricLogger(evaluator=evaluator)\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device= device, #TODO\n",
    "    max_epochs= max_epochs,  #TODO\n",
    "    train_data_loader= train_loader,  #TODO\n",
    "    network= net,  #TODO\n",
    "    optimizer= opt,  #TODO\n",
    "    loss_function= loss,  #TODO\n",
    "    train_handlers=[logger, ValidationHandler(1, evaluator)],\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(train_dat) // train_loader.batch_size\n",
    "if len(train_dat) % train_loader.batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "print(len(train_dat) , train_loader.batch_size, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def _end_iter(engine: Engine):\n",
    "    global step\n",
    "    loss = np.average([o[\"loss\"] for o in engine.state.output])\n",
    "    batch_len = len(engine.state.batch[0])\n",
    "    epoch = engine.state.epoch\n",
    "    epoch_len = engine.state.max_epochs\n",
    "    step_total = engine.state.iteration  \n",
    "    iter_losses.append(loss)\n",
    "    batch_sizes.append(batch_len)\n",
    "\n",
    "    print(f\"\\nepoch {epoch}/{epoch_len}, step {step}/{steps_per_epoch},  total step {step_total}/{steps_per_epoch*epoch_len}, training_loss = {loss:.4f}\", end='')\n",
    "    step += 1\n",
    "    \n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def _end_epoch(engine: Engine):\n",
    "    global step\n",
    "    overall_average_loss = np.average(iter_losses, weights=batch_sizes)\n",
    "    epoch_loss_values.append(overall_average_loss)    \n",
    "    # clear the contents of iter_losses and batch_sizes for the next epoch\n",
    "    del iter_losses[:]\n",
    "    del batch_sizes[:]\n",
    "    \n",
    "    dice = evaluator.state.metrics[\"val_mean_dice\"]   \n",
    "    metric_values.append(dice)\n",
    "    #progress_bar(engine.state.epoch, num_epochs, f\"Validation Metric: {dice:7.3}\")\n",
    "    print(f\" | avg loss: {overall_average_loss:.4f} Dice Metric: {dice:7.3}\", end='')\n",
    "    step = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/200, step 1/1,  total step 1/200, training_loss = 1.6050 | avg loss: 1.6050 Dice Metric:  0.0869\n",
      "epoch 2/200, step 1/1,  total step 2/200, training_loss = 1.5957 | avg loss: 1.5957 Dice Metric:  0.0879\n",
      "epoch 3/200, step 1/1,  total step 3/200, training_loss = 1.5878 | avg loss: 1.5878 Dice Metric:  0.0906\n",
      "epoch 4/200, step 1/1,  total step 4/200, training_loss = 1.5805 | avg loss: 1.5805 Dice Metric:  0.0919\n",
      "epoch 5/200, step 1/1,  total step 5/200, training_loss = 1.5736 | avg loss: 1.5736 Dice Metric:  0.0937\n",
      "epoch 6/200, step 1/1,  total step 6/200, training_loss = 1.5669 | avg loss: 1.5669 Dice Metric:  0.0975\n",
      "epoch 7/200, step 1/1,  total step 7/200, training_loss = 1.5605 | avg loss: 1.5605 Dice Metric:   0.101\n",
      "epoch 8/200, step 1/1,  total step 8/200, training_loss = 1.5544 | avg loss: 1.5544 Dice Metric:   0.107\n",
      "epoch 9/200, step 1/1,  total step 9/200, training_loss = 1.5485 | avg loss: 1.5485 Dice Metric:   0.113\n",
      "epoch 10/200, step 1/1,  total step 10/200, training_loss = 1.5426 | avg loss: 1.5426 Dice Metric:   0.119\n",
      "epoch 11/200, step 1/1,  total step 11/200, training_loss = 1.5369 | avg loss: 1.5369 Dice Metric:   0.125\n",
      "epoch 12/200, step 1/1,  total step 12/200, training_loss = 1.5313 | avg loss: 1.5313 Dice Metric:   0.131\n",
      "epoch 13/200, step 1/1,  total step 13/200, training_loss = 1.5257 | avg loss: 1.5257 Dice Metric:   0.138\n",
      "epoch 14/200, step 1/1,  total step 14/200, training_loss = 1.5202 | avg loss: 1.5202 Dice Metric:   0.143\n",
      "epoch 15/200, step 1/1,  total step 15/200, training_loss = 1.5148 | avg loss: 1.5148 Dice Metric:   0.151\n",
      "epoch 16/200, step 1/1,  total step 16/200, training_loss = 1.5095 | avg loss: 1.5095 Dice Metric:   0.158\n",
      "epoch 17/200, step 1/1,  total step 17/200, training_loss = 1.5042 | avg loss: 1.5042 Dice Metric:   0.165\n",
      "epoch 18/200, step 1/1,  total step 18/200, training_loss = 1.4990 | avg loss: 1.4990 Dice Metric:    0.17\n",
      "epoch 19/200, step 1/1,  total step 19/200, training_loss = 1.4939 | avg loss: 1.4939 Dice Metric:   0.174\n",
      "epoch 20/200, step 1/1,  total step 20/200, training_loss = 1.4887 | avg loss: 1.4887 Dice Metric:   0.179\n",
      "epoch 21/200, step 1/1,  total step 21/200, training_loss = 1.4836 | avg loss: 1.4836 Dice Metric:   0.183\n",
      "epoch 22/200, step 1/1,  total step 22/200, training_loss = 1.4785 | avg loss: 1.4785 Dice Metric:   0.185\n",
      "epoch 23/200, step 1/1,  total step 23/200, training_loss = 1.4734 | avg loss: 1.4734 Dice Metric:   0.189\n",
      "epoch 24/200, step 1/1,  total step 24/200, training_loss = 1.4683 | avg loss: 1.4683 Dice Metric:   0.192\n",
      "epoch 25/200, step 1/1,  total step 25/200, training_loss = 1.4634 | avg loss: 1.4634 Dice Metric:   0.195\n",
      "epoch 26/200, step 1/1,  total step 26/200, training_loss = 1.4584 | avg loss: 1.4584 Dice Metric:   0.197\n",
      "epoch 27/200, step 1/1,  total step 27/200, training_loss = 1.4535 | avg loss: 1.4535 Dice Metric:   0.201\n",
      "epoch 28/200, step 1/1,  total step 28/200, training_loss = 1.4487 | avg loss: 1.4487 Dice Metric:   0.204\n",
      "epoch 29/200, step 1/1,  total step 29/200, training_loss = 1.4439 | avg loss: 1.4439 Dice Metric:   0.208\n",
      "epoch 30/200, step 1/1,  total step 30/200, training_loss = 1.4392 | avg loss: 1.4392 Dice Metric:   0.213\n",
      "epoch 31/200, step 1/1,  total step 31/200, training_loss = 1.4344 | avg loss: 1.4344 Dice Metric:   0.216\n",
      "epoch 32/200, step 1/1,  total step 32/200, training_loss = 1.4297 | avg loss: 1.4297 Dice Metric:   0.222\n",
      "epoch 33/200, step 1/1,  total step 33/200, training_loss = 1.4249 | avg loss: 1.4249 Dice Metric:   0.227\n",
      "epoch 34/200, step 1/1,  total step 34/200, training_loss = 1.4200 | avg loss: 1.4200 Dice Metric:   0.232\n",
      "epoch 35/200, step 1/1,  total step 35/200, training_loss = 1.4151 | avg loss: 1.4151 Dice Metric:   0.235\n",
      "epoch 36/200, step 1/1,  total step 36/200, training_loss = 1.4101 | avg loss: 1.4101 Dice Metric:   0.241\n",
      "epoch 37/200, step 1/1,  total step 37/200, training_loss = 1.4051 | avg loss: 1.4051 Dice Metric:   0.248\n",
      "epoch 38/200, step 1/1,  total step 38/200, training_loss = 1.3999 | avg loss: 1.3999 Dice Metric:   0.253\n",
      "epoch 39/200, step 1/1,  total step 39/200, training_loss = 1.3947 | avg loss: 1.3947 Dice Metric:   0.259\n",
      "epoch 40/200, step 1/1,  total step 40/200, training_loss = 1.3894 | avg loss: 1.3894 Dice Metric:   0.265\n",
      "epoch 41/200, step 1/1,  total step 41/200, training_loss = 1.3840 | avg loss: 1.3840 Dice Metric:   0.272\n",
      "epoch 42/200, step 1/1,  total step 42/200, training_loss = 1.3786 | avg loss: 1.3786 Dice Metric:   0.277\n",
      "epoch 43/200, step 1/1,  total step 43/200, training_loss = 1.3732 | avg loss: 1.3732 Dice Metric:   0.282\n",
      "epoch 44/200, step 1/1,  total step 44/200, training_loss = 1.3677 | avg loss: 1.3677 Dice Metric:   0.287\n",
      "epoch 45/200, step 1/1,  total step 45/200, training_loss = 1.3622 | avg loss: 1.3622 Dice Metric:   0.292\n",
      "epoch 46/200, step 1/1,  total step 46/200, training_loss = 1.3566 | avg loss: 1.3566 Dice Metric:   0.299\n",
      "epoch 47/200, step 1/1,  total step 47/200, training_loss = 1.3511 | avg loss: 1.3511 Dice Metric:   0.305\n",
      "epoch 48/200, step 1/1,  total step 48/200, training_loss = 1.3456 | avg loss: 1.3456 Dice Metric:   0.312\n",
      "epoch 49/200, step 1/1,  total step 49/200, training_loss = 1.3400 | avg loss: 1.3400 Dice Metric:   0.318\n",
      "epoch 50/200, step 1/1,  total step 50/200, training_loss = 1.3345 | avg loss: 1.3345 Dice Metric:   0.325\n",
      "epoch 51/200, step 1/1,  total step 51/200, training_loss = 1.3290 | avg loss: 1.3290 Dice Metric:   0.333\n",
      "epoch 52/200, step 1/1,  total step 52/200, training_loss = 1.3235 | avg loss: 1.3235 Dice Metric:   0.343\n",
      "epoch 53/200, step 1/1,  total step 53/200, training_loss = 1.3180 | avg loss: 1.3180 Dice Metric:   0.351\n",
      "epoch 54/200, step 1/1,  total step 54/200, training_loss = 1.3125 | avg loss: 1.3125 Dice Metric:   0.359\n",
      "epoch 55/200, step 1/1,  total step 55/200, training_loss = 1.3070 | avg loss: 1.3070 Dice Metric:   0.366\n",
      "epoch 56/200, step 1/1,  total step 56/200, training_loss = 1.3015 | avg loss: 1.3015 Dice Metric:   0.371\n",
      "epoch 57/200, step 1/1,  total step 57/200, training_loss = 1.2961 | avg loss: 1.2961 Dice Metric:   0.376\n",
      "epoch 58/200, step 1/1,  total step 58/200, training_loss = 1.2906 | avg loss: 1.2906 Dice Metric:   0.379\n",
      "epoch 59/200, step 1/1,  total step 59/200, training_loss = 1.2851 | avg loss: 1.2851 Dice Metric:   0.382\n",
      "epoch 60/200, step 1/1,  total step 60/200, training_loss = 1.2796 | avg loss: 1.2796 Dice Metric:   0.384\n",
      "epoch 61/200, step 1/1,  total step 61/200, training_loss = 1.2742 | avg loss: 1.2742 Dice Metric:   0.385\n",
      "epoch 62/200, step 1/1,  total step 62/200, training_loss = 1.2687 | avg loss: 1.2687 Dice Metric:   0.386\n",
      "epoch 63/200, step 1/1,  total step 63/200, training_loss = 1.2632 | avg loss: 1.2632 Dice Metric:   0.388\n",
      "epoch 64/200, step 1/1,  total step 64/200, training_loss = 1.2576 | avg loss: 1.2576 Dice Metric:    0.39\n",
      "epoch 65/200, step 1/1,  total step 65/200, training_loss = 1.2521 | avg loss: 1.2521 Dice Metric:   0.391\n",
      "epoch 66/200, step 1/1,  total step 66/200, training_loss = 1.2466 | avg loss: 1.2466 Dice Metric:   0.395\n",
      "epoch 67/200, step 1/1,  total step 67/200, training_loss = 1.2410 | avg loss: 1.2410 Dice Metric:   0.399\n",
      "epoch 68/200, step 1/1,  total step 68/200, training_loss = 1.2354 | avg loss: 1.2354 Dice Metric:   0.401\n",
      "epoch 69/200, step 1/1,  total step 69/200, training_loss = 1.2299 | avg loss: 1.2299 Dice Metric:   0.404\n",
      "epoch 70/200, step 1/1,  total step 70/200, training_loss = 1.2243 | avg loss: 1.2243 Dice Metric:   0.405\n",
      "epoch 71/200, step 1/1,  total step 71/200, training_loss = 1.2188 | avg loss: 1.2188 Dice Metric:   0.407\n",
      "epoch 72/200, step 1/1,  total step 72/200, training_loss = 1.2132 | avg loss: 1.2132 Dice Metric:    0.41\n",
      "epoch 73/200, step 1/1,  total step 73/200, training_loss = 1.2077 | avg loss: 1.2077 Dice Metric:   0.411\n",
      "epoch 74/200, step 1/1,  total step 74/200, training_loss = 1.2022 | avg loss: 1.2022 Dice Metric:   0.414\n",
      "epoch 75/200, step 1/1,  total step 75/200, training_loss = 1.1967 | avg loss: 1.1967 Dice Metric:   0.412\n",
      "epoch 76/200, step 1/1,  total step 76/200, training_loss = 1.1912 | avg loss: 1.1912 Dice Metric:   0.412\n",
      "epoch 77/200, step 1/1,  total step 77/200, training_loss = 1.1856 | avg loss: 1.1856 Dice Metric:   0.412\n",
      "epoch 78/200, step 1/1,  total step 78/200, training_loss = 1.1801 | avg loss: 1.1801 Dice Metric:   0.412\n",
      "epoch 79/200, step 1/1,  total step 79/200, training_loss = 1.1745 | avg loss: 1.1745 Dice Metric:   0.412\n",
      "epoch 80/200, step 1/1,  total step 80/200, training_loss = 1.1689 | avg loss: 1.1689 Dice Metric:   0.413\n",
      "epoch 81/200, step 1/1,  total step 81/200, training_loss = 1.1633 | avg loss: 1.1633 Dice Metric:    0.41\n",
      "epoch 82/200, step 1/1,  total step 82/200, training_loss = 1.1577 | avg loss: 1.1577 Dice Metric:    0.41\n",
      "epoch 83/200, step 1/1,  total step 83/200, training_loss = 1.1521 | avg loss: 1.1521 Dice Metric:   0.407\n",
      "epoch 84/200, step 1/1,  total step 84/200, training_loss = 1.1466 | avg loss: 1.1466 Dice Metric:   0.406\n",
      "epoch 85/200, step 1/1,  total step 85/200, training_loss = 1.1410 | avg loss: 1.1410 Dice Metric:   0.403\n",
      "epoch 86/200, step 1/1,  total step 86/200, training_loss = 1.1355 | avg loss: 1.1355 Dice Metric:   0.402\n",
      "epoch 87/200, step 1/1,  total step 87/200, training_loss = 1.1299 | avg loss: 1.1299 Dice Metric:   0.399\n",
      "epoch 88/200, step 1/1,  total step 88/200, training_loss = 1.1244 | avg loss: 1.1244 Dice Metric:     0.4\n",
      "epoch 89/200, step 1/1,  total step 89/200, training_loss = 1.1189 | avg loss: 1.1189 Dice Metric:   0.398\n",
      "epoch 90/200, step 1/1,  total step 90/200, training_loss = 1.1134 | avg loss: 1.1134 Dice Metric:   0.399\n",
      "epoch 91/200, step 1/1,  total step 91/200, training_loss = 1.1080 | avg loss: 1.1080 Dice Metric:   0.399\n",
      "epoch 92/200, step 1/1,  total step 92/200, training_loss = 1.1025 | avg loss: 1.1025 Dice Metric:   0.396\n",
      "epoch 93/200, step 1/1,  total step 93/200, training_loss = 1.0970 | avg loss: 1.0970 Dice Metric:   0.398\n",
      "epoch 94/200, step 1/1,  total step 94/200, training_loss = 1.0916 | avg loss: 1.0916 Dice Metric:   0.393\n",
      "epoch 95/200, step 1/1,  total step 95/200, training_loss = 1.0863 | avg loss: 1.0863 Dice Metric:   0.401\n",
      "epoch 96/200, step 1/1,  total step 96/200, training_loss = 1.0809 | avg loss: 1.0809 Dice Metric:   0.389\n",
      "epoch 97/200, step 1/1,  total step 97/200, training_loss = 1.0756 | avg loss: 1.0756 Dice Metric:   0.397\n",
      "epoch 98/200, step 1/1,  total step 98/200, training_loss = 1.0702 | avg loss: 1.0702 Dice Metric:   0.397\n",
      "epoch 99/200, step 1/1,  total step 99/200, training_loss = 1.0649 | avg loss: 1.0649 Dice Metric:   0.392\n",
      "epoch 100/200, step 1/1,  total step 100/200, training_loss = 1.0595 | avg loss: 1.0595 Dice Metric:   0.401\n",
      "epoch 101/200, step 1/1,  total step 101/200, training_loss = 1.0542 | avg loss: 1.0542 Dice Metric:   0.398\n",
      "epoch 102/200, step 1/1,  total step 102/200, training_loss = 1.0489 | avg loss: 1.0489 Dice Metric:   0.398\n",
      "epoch 103/200, step 1/1,  total step 103/200, training_loss = 1.0437 | avg loss: 1.0437 Dice Metric:   0.406\n",
      "epoch 104/200, step 1/1,  total step 104/200, training_loss = 1.0385 | avg loss: 1.0385 Dice Metric:   0.402\n",
      "epoch 105/200, step 1/1,  total step 105/200, training_loss = 1.0332 | avg loss: 1.0332 Dice Metric:   0.404\n",
      "epoch 106/200, step 1/1,  total step 106/200, training_loss = 1.0279 | avg loss: 1.0279 Dice Metric:   0.408\n",
      "epoch 107/200, step 1/1,  total step 107/200, training_loss = 1.0229 | avg loss: 1.0229 Dice Metric:   0.396\n",
      "epoch 108/200, step 1/1,  total step 108/200, training_loss = 1.0178 | avg loss: 1.0178 Dice Metric:   0.411\n",
      "epoch 109/200, step 1/1,  total step 109/200, training_loss = 1.0128 | avg loss: 1.0128 Dice Metric:   0.402\n",
      "epoch 110/200, step 1/1,  total step 110/200, training_loss = 1.0077 | avg loss: 1.0077 Dice Metric:   0.401\n",
      "epoch 111/200, step 1/1,  total step 111/200, training_loss = 1.0025 | avg loss: 1.0025 Dice Metric:    0.41\n",
      "epoch 112/200, step 1/1,  total step 112/200, training_loss = 0.9973 | avg loss: 0.9973 Dice Metric:   0.398\n",
      "epoch 113/200, step 1/1,  total step 113/200, training_loss = 0.9924 | avg loss: 0.9924 Dice Metric:   0.402\n",
      "epoch 114/200, step 1/1,  total step 114/200, training_loss = 0.9873 | avg loss: 0.9873 Dice Metric:   0.406\n",
      "epoch 115/200, step 1/1,  total step 115/200, training_loss = 0.9821 | avg loss: 0.9821 Dice Metric:   0.402\n",
      "epoch 116/200, step 1/1,  total step 116/200, training_loss = 0.9772 | avg loss: 0.9772 Dice Metric:   0.406\n",
      "epoch 117/200, step 1/1,  total step 117/200, training_loss = 0.9723 | avg loss: 0.9723 Dice Metric:   0.401\n",
      "epoch 118/200, step 1/1,  total step 118/200, training_loss = 0.9672 | avg loss: 0.9672 Dice Metric:   0.404\n",
      "epoch 119/200, step 1/1,  total step 119/200, training_loss = 0.9622 | avg loss: 0.9622 Dice Metric:     0.4\n",
      "epoch 120/200, step 1/1,  total step 120/200, training_loss = 0.9574 | avg loss: 0.9574 Dice Metric:   0.401\n",
      "epoch 121/200, step 1/1,  total step 121/200, training_loss = 0.9524 | avg loss: 0.9524 Dice Metric:   0.407\n",
      "epoch 122/200, step 1/1,  total step 122/200, training_loss = 0.9475 | avg loss: 0.9475 Dice Metric:   0.397\n",
      "epoch 123/200, step 1/1,  total step 123/200, training_loss = 0.9427 | avg loss: 0.9427 Dice Metric:   0.403\n",
      "epoch 124/200, step 1/1,  total step 124/200, training_loss = 0.9380 | avg loss: 0.9380 Dice Metric:   0.395\n",
      "epoch 125/200, step 1/1,  total step 125/200, training_loss = 0.9334 | avg loss: 0.9334 Dice Metric:     0.4\n",
      "epoch 126/200, step 1/1,  total step 126/200, training_loss = 0.9292 | avg loss: 0.9292 Dice Metric:   0.398\n",
      "epoch 127/200, step 1/1,  total step 127/200, training_loss = 0.9246 | avg loss: 0.9246 Dice Metric:   0.402\n",
      "epoch 128/200, step 1/1,  total step 128/200, training_loss = 0.9190 | avg loss: 0.9190 Dice Metric:   0.401\n",
      "epoch 129/200, step 1/1,  total step 129/200, training_loss = 0.9147 | avg loss: 0.9147 Dice Metric:   0.402\n",
      "epoch 130/200, step 1/1,  total step 130/200, training_loss = 0.9100 | avg loss: 0.9100 Dice Metric:   0.397\n",
      "epoch 131/200, step 1/1,  total step 131/200, training_loss = 0.9046 | avg loss: 0.9046 Dice Metric:   0.402\n",
      "epoch 132/200, step 1/1,  total step 132/200, training_loss = 0.9004 | avg loss: 0.9004 Dice Metric:   0.394\n",
      "epoch 133/200, step 1/1,  total step 133/200, training_loss = 0.8955 | avg loss: 0.8955 Dice Metric:   0.396\n",
      "epoch 134/200, step 1/1,  total step 134/200, training_loss = 0.8907 | avg loss: 0.8907 Dice Metric:     0.4\n",
      "epoch 135/200, step 1/1,  total step 135/200, training_loss = 0.8862 | avg loss: 0.8862 Dice Metric:   0.392\n",
      "epoch 136/200, step 1/1,  total step 136/200, training_loss = 0.8815 | avg loss: 0.8815 Dice Metric:     0.4\n",
      "epoch 137/200, step 1/1,  total step 137/200, training_loss = 0.8770 | avg loss: 0.8770 Dice Metric:   0.386\n",
      "epoch 138/200, step 1/1,  total step 138/200, training_loss = 0.8721 | avg loss: 0.8721 Dice Metric:   0.397\n",
      "epoch 139/200, step 1/1,  total step 139/200, training_loss = 0.8678 | avg loss: 0.8678 Dice Metric:   0.387\n",
      "epoch 140/200, step 1/1,  total step 140/200, training_loss = 0.8632 | avg loss: 0.8632 Dice Metric:   0.397\n",
      "epoch 141/200, step 1/1,  total step 141/200, training_loss = 0.8586 | avg loss: 0.8586 Dice Metric:   0.384\n",
      "epoch 142/200, step 1/1,  total step 142/200, training_loss = 0.8543 | avg loss: 0.8543 Dice Metric:   0.396\n",
      "epoch 143/200, step 1/1,  total step 143/200, training_loss = 0.8494 | avg loss: 0.8494 Dice Metric:   0.389\n",
      "epoch 144/200, step 1/1,  total step 144/200, training_loss = 0.8447 | avg loss: 0.8447 Dice Metric:   0.387\n",
      "epoch 145/200, step 1/1,  total step 145/200, training_loss = 0.8402 | avg loss: 0.8402 Dice Metric:   0.395\n",
      "epoch 146/200, step 1/1,  total step 146/200, training_loss = 0.8357 | avg loss: 0.8357 Dice Metric:   0.386\n",
      "epoch 147/200, step 1/1,  total step 147/200, training_loss = 0.8312 | avg loss: 0.8312 Dice Metric:   0.392\n",
      "epoch 148/200, step 1/1,  total step 148/200, training_loss = 0.8266 | avg loss: 0.8266 Dice Metric:   0.382\n",
      "epoch 149/200, step 1/1,  total step 149/200, training_loss = 0.8221 | avg loss: 0.8221 Dice Metric:   0.389\n",
      "epoch 150/200, step 1/1,  total step 150/200, training_loss = 0.8178 | avg loss: 0.8178 Dice Metric:   0.386\n",
      "epoch 151/200, step 1/1,  total step 151/200, training_loss = 0.8133 | avg loss: 0.8133 Dice Metric:   0.385\n",
      "epoch 152/200, step 1/1,  total step 152/200, training_loss = 0.8088 | avg loss: 0.8088 Dice Metric:   0.387\n",
      "epoch 153/200, step 1/1,  total step 153/200, training_loss = 0.8041 | avg loss: 0.8041 Dice Metric:   0.385\n",
      "epoch 154/200, step 1/1,  total step 154/200, training_loss = 0.7999 | avg loss: 0.7999 Dice Metric:   0.387\n",
      "epoch 155/200, step 1/1,  total step 155/200, training_loss = 0.7958 | avg loss: 0.7958 Dice Metric:   0.379\n",
      "epoch 156/200, step 1/1,  total step 156/200, training_loss = 0.7915 | avg loss: 0.7915 Dice Metric:   0.393\n",
      "epoch 157/200, step 1/1,  total step 157/200, training_loss = 0.7876 | avg loss: 0.7876 Dice Metric:   0.377\n",
      "epoch 158/200, step 1/1,  total step 158/200, training_loss = 0.7832 | avg loss: 0.7832 Dice Metric:   0.394\n",
      "epoch 159/200, step 1/1,  total step 159/200, training_loss = 0.7791 | avg loss: 0.7791 Dice Metric:   0.381\n",
      "epoch 160/200, step 1/1,  total step 160/200, training_loss = 0.7747 | avg loss: 0.7747 Dice Metric:   0.381\n",
      "epoch 161/200, step 1/1,  total step 161/200, training_loss = 0.7699 | avg loss: 0.7699 Dice Metric:   0.392\n",
      "epoch 162/200, step 1/1,  total step 162/200, training_loss = 0.7657 | avg loss: 0.7657 Dice Metric:   0.373\n",
      "epoch 163/200, step 1/1,  total step 163/200, training_loss = 0.7615 | avg loss: 0.7615 Dice Metric:   0.391\n",
      "epoch 164/200, step 1/1,  total step 164/200, training_loss = 0.7572 | avg loss: 0.7572 Dice Metric:    0.38\n",
      "epoch 165/200, step 1/1,  total step 165/200, training_loss = 0.7525 | avg loss: 0.7525 Dice Metric:   0.374\n",
      "epoch 166/200, step 1/1,  total step 166/200, training_loss = 0.7484 | avg loss: 0.7484 Dice Metric:   0.391\n",
      "epoch 167/200, step 1/1,  total step 167/200, training_loss = 0.7446 | avg loss: 0.7446 Dice Metric:   0.373\n",
      "epoch 168/200, step 1/1,  total step 168/200, training_loss = 0.7400 | avg loss: 0.7400 Dice Metric:   0.379\n",
      "epoch 169/200, step 1/1,  total step 169/200, training_loss = 0.7355 | avg loss: 0.7355 Dice Metric:   0.381\n",
      "epoch 170/200, step 1/1,  total step 170/200, training_loss = 0.7317 | avg loss: 0.7317 Dice Metric:   0.369\n",
      "epoch 171/200, step 1/1,  total step 171/200, training_loss = 0.7277 | avg loss: 0.7277 Dice Metric:   0.384\n",
      "epoch 172/200, step 1/1,  total step 172/200, training_loss = 0.7235 | avg loss: 0.7235 Dice Metric:   0.378\n",
      "epoch 173/200, step 1/1,  total step 173/200, training_loss = 0.7192 | avg loss: 0.7192 Dice Metric:   0.369\n",
      "epoch 174/200, step 1/1,  total step 174/200, training_loss = 0.7153 | avg loss: 0.7153 Dice Metric:   0.387\n",
      "epoch 175/200, step 1/1,  total step 175/200, training_loss = 0.7119 | avg loss: 0.7119 Dice Metric:   0.369\n",
      "epoch 176/200, step 1/1,  total step 176/200, training_loss = 0.7077 | avg loss: 0.7077 Dice Metric:   0.377\n",
      "epoch 177/200, step 1/1,  total step 177/200, training_loss = 0.7037 | avg loss: 0.7037 Dice Metric:   0.374\n",
      "epoch 178/200, step 1/1,  total step 178/200, training_loss = 0.7000 | avg loss: 0.7000 Dice Metric:    0.37\n",
      "epoch 179/200, step 1/1,  total step 179/200, training_loss = 0.6959 | avg loss: 0.6959 Dice Metric:   0.381\n",
      "epoch 180/200, step 1/1,  total step 180/200, training_loss = 0.6912 | avg loss: 0.6912 Dice Metric:   0.372\n",
      "epoch 181/200, step 1/1,  total step 181/200, training_loss = 0.6873 | avg loss: 0.6873 Dice Metric:   0.374\n",
      "epoch 182/200, step 1/1,  total step 182/200, training_loss = 0.6838 | avg loss: 0.6838 Dice Metric:   0.373\n",
      "epoch 183/200, step 1/1,  total step 183/200, training_loss = 0.6799 | avg loss: 0.6799 Dice Metric:   0.376\n",
      "epoch 184/200, step 1/1,  total step 184/200, training_loss = 0.6751 | avg loss: 0.6751 Dice Metric:   0.371\n",
      "epoch 185/200, step 1/1,  total step 185/200, training_loss = 0.6713 | avg loss: 0.6713 Dice Metric:   0.377\n",
      "epoch 186/200, step 1/1,  total step 186/200, training_loss = 0.6681 | avg loss: 0.6681 Dice Metric:   0.374\n",
      "epoch 187/200, step 1/1,  total step 187/200, training_loss = 0.6640 | avg loss: 0.6640 Dice Metric:   0.365\n",
      "epoch 188/200, step 1/1,  total step 188/200, training_loss = 0.6600 | avg loss: 0.6600 Dice Metric:   0.375\n",
      "epoch 189/200, step 1/1,  total step 189/200, training_loss = 0.6570 | avg loss: 0.6570 Dice Metric:   0.366\n",
      "epoch 190/200, step 1/1,  total step 190/200, training_loss = 0.6536 | avg loss: 0.6536 Dice Metric:   0.373\n",
      "epoch 191/200, step 1/1,  total step 191/200, training_loss = 0.6503 | avg loss: 0.6503 Dice Metric:   0.371\n",
      "epoch 192/200, step 1/1,  total step 192/200, training_loss = 0.6469 | avg loss: 0.6469 Dice Metric:   0.362\n",
      "epoch 193/200, step 1/1,  total step 193/200, training_loss = 0.6416 | avg loss: 0.6416 Dice Metric:   0.378\n",
      "epoch 194/200, step 1/1,  total step 194/200, training_loss = 0.6374 | avg loss: 0.6374 Dice Metric:   0.368\n",
      "epoch 195/200, step 1/1,  total step 195/200, training_loss = 0.6346 | avg loss: 0.6346 Dice Metric:   0.367\n",
      "epoch 196/200, step 1/1,  total step 196/200, training_loss = 0.6307 | avg loss: 0.6307 Dice Metric:   0.376\n",
      "epoch 197/200, step 1/1,  total step 197/200, training_loss = 0.6266 | avg loss: 0.6266 Dice Metric:   0.361\n",
      "epoch 198/200, step 1/1,  total step 198/200, training_loss = 0.6227 | avg loss: 0.6227 Dice Metric:   0.372\n",
      "epoch 199/200, step 1/1,  total step 199/200, training_loss = 0.6194 | avg loss: 0.6194 Dice Metric:   0.369\n",
      "epoch 200/200, step 1/1,  total step 200/200, training_loss = 0.6155 | avg loss: 0.6155 Dice Metric:   0.362"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    " \n",
    "ax[0].plot(epoch_loss_values)\n",
    "ax[0].set_title(\"epoch Loss\")\n",
    "ax[0].set_ylim(0,1)\n",
    "ax[1].plot(metric_values)\n",
    "ax[1].set_title(\"epoch matric\")\n",
    "ax[1].set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCE-Dice with \n",
    "# AutoEncoder( spatial_dims =2, in_channels=1, out_channels=1, \\\n",
    "#               channels=(4, 8, 16, 32),  strides=(2, 2, 2, 2), ) \n",
    "# 200epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice with \n",
    "# AutoEncoder( spatial_dims =2, in_channels=1, out_channels=1, \\\n",
    "#               channels=(4, 8, 16, 32),  strides=(2, 2, 2, 2), ) \n",
    "# 200epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat trials \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation\n",
    "- [01_getting started](./01_getting.ipynb)\n",
    "\n",
    "- [02_pipeline_01](./02_pipeline_01.ipynb)\n",
    "- [02_pipeline_02 ](./02_pipeline_02.ipynb)\n",
    "- [02_pipeline_03](./02_pipeline_03.ipynb)\n",
    "- [02_pipeline_04 Next ](./02_pipeline_04.ipynb)\n",
    "\n",
    "- [03_brain_gan ](./03_brain_gan_01.ipynb)\n",
    "\n",
    "- [04_spleen_segment](./04_spleen_segment.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac baseline](./05_challenge_cardiac_baseline.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac workspace](./05_challenge_cardiac_workspace.ipynb) \n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "moani_bootcamp_2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
